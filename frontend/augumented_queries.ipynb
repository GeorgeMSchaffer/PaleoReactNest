{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import json\n",
    "from pathlib import Path\n",
    "from langchain import hub\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.docstore.document import Document\n",
    "from trulens_eval import TruChain, Tru\n",
    "from trulens_eval.feedback.provider import OpenAI\n",
    "from trulens_eval import Feedback\n",
    "import numpy as np\n",
    "\n",
    "# Initialize TruLens\n",
    "tru = Tru()\n",
    "tru.reset_database()\n",
    "\n",
    "# Function to read JSON files from PROJECT_DATA folder\n",
    "def read_json_files(folder_path):\n",
    "    json_files = Path(folder_path).glob('*.json')\n",
    "    data = []\n",
    "    for json_file in json_files:\n",
    "        with open(json_file, 'r') as file:\n",
    "            data.append(json.load(file))\n",
    "    return data\n",
    "\n",
    "# Read JSON files from PROJECT_DATA folder\n",
    "project_data_folder = 'PROJECT_DATA'\n",
    "data = read_json_files(project_data_folder)\n",
    "\n",
    "# Display the loaded data\n",
    "print(f\"Loaded {len(data)} JSON files from {project_data_folder}\")\n",
    "\n",
    "# Initialize LangChain components\n",
    "chat_openai = ChatOpenAI()\n",
    "embeddings = OpenAIEmbeddings()\n",
    "text_splitter = RecursiveCharacterTextSplitter()\n",
    "vector_store = Chroma()\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "# Function to perform augmented queries\n",
    "def augmented_query(query):\n",
    "    # Split the query into chunks\n",
    "    chunks = text_splitter.split_text(query)\n",
    "    \n",
    "    # Embed the chunks\n",
    "    embedded_chunks = [embeddings.embed(chunk) for chunk in chunks]\n",
    "    \n",
    "    # Store the embeddings in the vector store\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        vector_store.add_document(Document(content=chunk, embedding=embedded_chunks[i]))\n",
    "    \n",
    "    # Perform the query\n",
    "    response = chat_openai.query(query)\n",
    "    \n",
    "    # Parse the response\n",
    "    parsed_response = output_parser.parse(response)\n",
    "    \n",
    "    return parsed_response\n",
    "\n",
    "# Example usage of augmented_query function\n",
    "query = \"What are the most common species in the permian interval?\"\n",
    "response = augmented_query(query)\n",
    "print(\"Query Response:\", response)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
